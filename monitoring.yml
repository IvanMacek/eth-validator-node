---
- name: Start & configure monitoring services
  hosts: ethereum
  become: true
  roles:
  - role: cloudalchemy.node_exporter

  - role: cloudalchemy.alertmanager
    vars:
      alertmanager_version: latest
      alertmanager_receivers:
        - name: empty
        - name: pagerduty-general
          pagerduty_configs:
            - service_key: "{{ alertmanager_pagerduty_general_key }}"
        - name: pagerduty-critical
          pagerduty_configs:
            - service_key: "{{ alertmanager_pagerduty_critical_key }}"
      alertmanager_route:
        group_by: ['service']
        receiver: pagerduty-general
        routes:
        - matchers: [ 'alertname="Watchdog"' ]
          receiver: empty
        - matchers: [ 'severity="critical"' ]
          receiver: pagerduty-critical
    when: alertmanager_enabled == true

  - role: cloudalchemy.prometheus
    vars:
      prometheus_version: latest
      prometheus_storage_retention: 15d
      prometheus_global:
        scrape_interval: 15s
        evaluation_interval: 15s
      prometheus_scrape_configs:
      - job_name: lhbn
        metrics_path: /metrics    
        static_configs:
          - targets: [ 'localhost:5054' ]
      - job_name: lhvc
        metrics_path: /metrics    
        static_configs:
          - targets: [ 'localhost:5064' ]
      - job_name: geth
        metrics_path: /debug/metrics/prometheus
        static_configs:
        - targets: [ 'localhost:6060' ]
      - job_name: node
        metrics_path: /metrics
        static_configs:
        - targets: [ 'localhost:9100' ]
      prometheus_alertmanager_config:
      - static_configs:
        - targets: [ 'localhost:9093' ]
      prometheus_alert_rules:
      - alert: Watchdog
        expr: vector(1)
        for: 10m
        labels:
          severity: warning
        annotations:
          description: 'This is an alert meant to ensure that the entire alerting pipeline is functional.
            This alert is always firing, therefore it should always be firing in Alertmanager
            and always fire against a receiver. There are integrations with various notification
            mechanisms that send a notification when this alert is not firing. For example the
            "DeadMansSnitch" integration in PagerDuty.'
          summary: 'Ensure entire alerting pipeline is functional'
      - alert: InstanceDown
        expr: "up == 0"
        for: 5m
        labels:
          severity: critical
        annotations:
          description: "{% raw %}{{ $labels.instance }} of job {{ $labels.job }} has been down for more than 5 minutes.{% endraw %}"
          summary: "{% raw %}Instance {{ $labels.instance }} down{% endraw %}"
      - alert: CriticalCPULoad
        expr: '100 - (avg by (instance) (irate(node_cpu_seconds_total{job="node",mode="idle"}[5m])) * 100) > 96'
        for: 2m
        labels:
          severity: critical
        annotations:
          description: "{% raw %}{{ $labels.instance }} of job {{ $labels.job }} has Critical CPU load for more than 2 minutes.{% endraw %}"
          summary: "{% raw %}Instance {{ $labels.instance }} - Critical CPU load{% endraw %}"
      - alert: CriticalRAMUsage
        expr: '(1 - ((node_memory_MemFree_bytes + node_memory_Buffers_bytes + node_memory_Cached_bytes) / node_memory_MemTotal_bytes)) * 100 > 98'
        for: 5m
        labels:
          severity: critical
        annotations:
          description: "{% raw %}{{ $labels.instance }} has Critical Memory Usage more than 5 minutes.{% endraw %}"
          summary: "{% raw %}Instance {{ $labels.instance }} has Critical Memory Usage{% endraw %}"
      - alert: CriticalDiskSpace
        expr: 'node_filesystem_free_bytes{mountpoint!~"^/run(/.*|$)",fstype!~"(squashfs|fuse.*)",job="node"} / node_filesystem_size_bytes{job="node"} < 0.1'
        for: 4m
        labels:
          severity: critical
        annotations:
          description: "{% raw %}{{ $labels.instance }} of job {{ $labels.job }} has less than 10% space remaining.{% endraw %}"
          summary: "{% raw %}Instance {{ $labels.instance }} - Critical disk space usage{% endraw %}"
      - alert: RebootRequired
        expr: "node_reboot_required > 0"
        labels:
          severity: warning
        annotations:
          description: "{% raw %}{{ $labels.instance }} requires a reboot.{% endraw %}"
          summary: "{% raw %}Instance {{ $labels.instance }} - reboot required{% endraw %}"
      - alert: ClockSkewDetected
        expr: 'abs(node_timex_offset_seconds) * 1000 > 30'
        for: 2m
        labels:
          severity: warning
        annotations:
          description: "{% raw %}Clock skew detected on {{ $labels.instance }}. Ensure NTP is configured correctly on this host.{% endraw %}"
          summary: "{% raw %}Instance {{ $labels.instance }} - Clock skew detected{% endraw %}"
      - alert: LateAttestation
        expr: "validator_monitor_prev_epoch_attestation_block_min_inclusion_distance > 1"
        labels:
          severity: warning
        annotations:
          description: "{% raw %}Validator {{ $labels.validator }} has produced late attestation resulting in lower ETH earnings.{% endraw %}"
          summary: "{% raw %}Validator {{ $labels.instance }} - Late attestation{% endraw %}"
      - alert: MissedAttestation
        expr: "validator_monitor_prev_epoch_attestations_total != 1"
        labels:
          severity: critical
        annotations:
          description: "{% raw %}Validator {{ $labels.validator }} missed attesting resulting in ETH penalties.{% endraw %}"
          summary: "{% raw %}Validator {{ $labels.instance }} - Missed attestation{% endraw %}"
      - alert: ProposerSlashing
        expr: "validator_monitor_prev_epoch_proposer_slashings_total > 0"
        labels:
          severity: critical
        annotations:
          description: "{% raw %}Validator {{ $labels.validator }} was slashed for a produced proposal resulting in significant ETH penalties.{% endraw %}"
          summary: "{% raw %}Validator {{ $labels.instance }} - Proposer slashing{% endraw %}"
      - alert: AttesterSlashing
        expr: "validator_monitor_prev_epoch_attester_slashings_total > 0"
        labels:
          severity: critical
        annotations:
          description: "{% raw %}Validator {{ $labels.validator }} was slashed for produced attestation resulting in significant ETH penalties.{% endraw %}"
          summary: "{% raw %}Validator {{ $labels.instance }} - Attester slashing{% endraw %}"   

  - role: cloudalchemy.grafana
    vars:
      grafana_security:
        admin_user: admin
        admin_password: admin # You'll be asked to change
      grafana_auth:
        anonymous:
          enabled: false
      grafana_datasources:
      - name: prometheus
        type: prometheus
        access: proxy
        url: http://localhost:9090
      grafana_dashboards:
      - dashboard_id: '14053' # Geth
        revision_id: '1'
        datasource: prometheus
      - dashboard_id: '1860' # Node Exporter
        revision_id: '25'
        datasource: prometheus

  tasks:
  - name: Fix job parameter in the Geth dashboard
    replace:
      dest: "/var/lib/grafana/dashboards/14053.json"
      regexp: "\\${VAR_JOB}"
      replace: "geth"

  - name: Allow traffic to Grafana
    ufw:
      rule: allow
      port: "3000"
      proto: tcp

  - name: Allow traffic to Prometheus
    ufw:
      rule: allow
      port: "9090"
      proto: tcp
